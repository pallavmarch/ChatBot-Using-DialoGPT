{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AHO_dDCowE9a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sqESlNZhkA6M"
      },
      "outputs": [],
      "source": [
        "class ChatBot:\n",
        "    def __init__(self):\n",
        "\n",
        "        link=\"microsoft/DialoGPT-large\"\n",
        "        self.chat_history_ids = None\n",
        "        self.bot_input_ids = None\n",
        "        self.end_chat = False\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(link)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(link)\n",
        "        self.greet_user()\n",
        "\n",
        "    def greet_user(self):\n",
        "\n",
        "        print(\"ChatBot : Welcome, I am a ChatBot, ready to assist you.\\n Type 'bye', 'quit', or 'exit' to end the chat\\n\")\n",
        "\n",
        "    def user_input(self):\n",
        "        text = input(\"User    : \")\n",
        "        if text.lower().strip() in ['bye', 'quit', 'exit']:\n",
        "            self.end_chat = True\n",
        "            print('Quitting ChatBot')\n",
        "        else:\n",
        "            self.new_user_input_ids = self.tokenizer.encode(text + self.tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    def generate_response(self):\n",
        "        if self.chat_history_ids is not None:\n",
        "            self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1)\n",
        "        else:\n",
        "            self.bot_input_ids = self.new_user_input_ids\n",
        "\n",
        "        self.chat_history_ids = self.model.generate(\n",
        "            self.bot_input_ids, max_length=1000, pad_token_id=self.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        response = self.tokenizer.decode(\n",
        "            self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        if not response:\n",
        "            response = self.get_fallback_response()\n",
        "\n",
        "        print('ChatBot :', response)\n",
        "\n",
        "    def get_fallback_response(self):\n",
        "        i = -1\n",
        "        response = self.tokenizer.decode(\n",
        "            self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        while not response:\n",
        "            i -= 1\n",
        "            response = self.tokenizer.decode(\n",
        "                self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], skip_special_tokens=True\n",
        "            )\n",
        "\n",
        "\n",
        "        if response.strip() == '?':\n",
        "            return \"I don't know\"\n",
        "        else:\n",
        "            return \"Okay\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfGkVfCHkb6y",
        "outputId": "6b501c18-3d41-44cd-dac0-0f3f3b4ea7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatBot : Welcome, I am a ChatBot, ready to assist you.\n",
            " Type 'bye', 'quit', or 'exit' to end the chat\n",
            "\n",
            "User    : Hey\n",
            "ChatBot : Hey, how are you?\n",
            "User    : I'm good. How are you?\n",
            "ChatBot : I'm good.\n",
            "User    : Want to help on coding?\n",
            "ChatBot : I can help.\n",
            "User    : Do you code?\n",
            "ChatBot : I can code.\n",
            "User    : Which language do you code in?\n",
            "ChatBot : C, but I'm not a programmer.\n",
            "User    : You tried using C++?\n",
            "ChatBot : I can code in C.\n",
            "User    : What is the best language to code in?\n",
            "ChatBot : C is the best language to code in.\n",
            "User    : Do you like tea?\n",
            "ChatBot : I like tea.\n",
            "User    : Which type of tea do you prefer?\n",
            "ChatBot : C is the best.\n"
          ]
        }
      ],
      "source": [
        "bot = ChatBot()\n",
        "\n",
        "while True:\n",
        "    bot.user_input()\n",
        "    if bot.end_chat:\n",
        "        break\n",
        "    bot.generate_response()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}